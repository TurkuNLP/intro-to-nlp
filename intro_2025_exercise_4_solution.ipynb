{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/intro-to-nlp/blob/master/intro_2025_exercise_4_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise task 4: creating a dataset from corpus data (solution)\n",
        "\n",
        "This notebook shows an example solution for exercise 4.\n"
      ],
      "metadata": {
        "id": "0RscBh6fv3O_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Setup"
      ],
      "metadata": {
        "id": "sgDc1GmswCvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet datasets"
      ],
      "metadata": {
        "id": "cfrNVDZksTnX"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "import datasets"
      ],
      "metadata": {
        "id": "p9SqpAiCFFX3"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Process data into dataset"
      ],
      "metadata": {
        "id": "G-RxtZUNw3Ew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download raw data from given URLs to local drive"
      ],
      "metadata": {
        "id": "79xGo35Nxnu7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "9r2Fd-dsks9A"
      },
      "outputs": [],
      "source": [
        "!wget --quiet -nc http://dl.turkunlp.org/TKO_7095_2023/imdb-positives.txt\n",
        "!wget --quiet -nc http://dl.turkunlp.org/TKO_7095_2023/imdb-negatives.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read in one text per line format"
      ],
      "metadata": {
        "id": "8laPFhDOxtbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positive_texts = open('imdb-positives.txt').readlines()\n",
        "negative_texts = open('imdb-negatives.txt').readlines()"
      ],
      "metadata": {
        "id": "bR_xONuqk14p"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reformat as list of dictionaries with `text` and `label`"
      ],
      "metadata": {
        "id": "cJNXXJkNx7H9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positive_examples = [{ 'text': text, 'label': 'positive' } for text in positive_texts]\n",
        "negative_examples = [{ 'text': text, 'label': 'negative' } for text in negative_texts]"
      ],
      "metadata": {
        "id": "pUM_F9cjlFSF"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine these"
      ],
      "metadata": {
        "id": "JbpuwzMZyIvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_examples = positive_examples + negative_examples"
      ],
      "metadata": {
        "id": "4pqpP0ydlWtk"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important**! Shuffle your data so that you don't have all positives first followed by all negatives"
      ],
      "metadata": {
        "id": "3un3DMB0yNYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(all_examples)"
      ],
      "metadata": {
        "id": "g6Mf_Peklenu"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split into train, validation and test sets"
      ],
      "metadata": {
        "id": "fN0QoW77yVeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_size = len(all_examples)\n",
        "\n",
        "train_size = int(0.8*total_size)\n",
        "valid_size = int(0.1*total_size)\n",
        "test_size = total_size - train_size - valid_size\n",
        "\n",
        "train_examples = all_examples[:train_size]\n",
        "valid_examples = all_examples[train_size:train_size+valid_size]\n",
        "test_examples = all_examples[train_size+valid_size:]"
      ],
      "metadata": {
        "id": "Rj0W1l8olhuS"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_data_integrity(train, valid, test):\n",
        "  print(\"Examples in train, valid and test sets:\")\n",
        "  print(len(train), len(valid), len(test))\n",
        "  print()\n",
        "  print(\"Proportion of 'positive' in the datasets:\")\n",
        "  print(\"Train:\", len([example['label'] for example in train if example['label']==\"positive\"])/len(train))\n",
        "  print(\"Valid:\", len([example['label'] for example in valid if example['label']==\"positive\"])/len(valid))\n",
        "  print(\"Test:\",len([example['label'] for example in test if example['label']==\"positive\"])/len(test))"
      ],
      "metadata": {
        "id": "j3WSMrqUMwg-"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_data_integrity(train_examples, valid_examples, test_examples)"
      ],
      "metadata": {
        "id": "Njw8-nboNMlF",
        "outputId": "63d2ac68-16c2-4dfe-8784-5ec45472e0db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples in train, valid and test sets:\n",
            "40000 5000 5000\n",
            "\n",
            "Proportion of 'positive' in the datasets:\n",
            "Train: 0.49945\n",
            "Valid: 0.4974\n",
            "Test: 0.507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ALTERNATIVE TO SPLITTING USING SKLEARN\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "all_labels = [example['label'] for example in all_examples]\n",
        "\n",
        "train_examples, test_examples = train_test_split(all_examples,\n",
        "                                                 train_size=0.8,\n",
        "                                                 random_state=42,\n",
        "                                                 stratify=all_labels)\n",
        "\n",
        "test_labels = [example['label'] for example in test_examples]\n",
        "\n",
        "test_examples, valid_examples = train_test_split(test_examples,\n",
        "                                                 train_size=0.5,\n",
        "                                                 random_state=42,\n",
        "                                                 stratify=test_labels)"
      ],
      "metadata": {
        "id": "tgJ_cm91D8Nl"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_data_integrity(train_examples, valid_examples, test_examples)"
      ],
      "metadata": {
        "id": "A_WNdXI-LN1R",
        "outputId": "a78c5136-b8ec-45d6-bda7-cd6c32e83553",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples in train, valid and test sets:\n",
            "40000 5000 5000\n",
            "\n",
            "Proportion of 'positive' in the datasets:\n",
            "Train: 0.5\n",
            "Valid: 0.5\n",
            "Test: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reformat as datasets. Notice that `Dataset.from_dict` expects a dictionary of lists rather than a list of dictionaries."
      ],
      "metadata": {
        "id": "J5anuyKlyZHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataset(examples):\n",
        "  texts, labels = [], []\n",
        "  for e in examples:\n",
        "    texts.append(e['text'])\n",
        "    labels.append(e['label'])\n",
        "  data = {\n",
        "      'text': texts,\n",
        "      'label': labels\n",
        "  }\n",
        "  return datasets.Dataset.from_dict(data)\n",
        "\n",
        "\n",
        "train = make_dataset(train_examples)\n",
        "valid = make_dataset(valid_examples)\n",
        "test = make_dataset(test_examples)"
      ],
      "metadata": {
        "id": "WYPqGBOwEwhK"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create `DatasetDict` to wrap the `Dataset` objects"
      ],
      "metadata": {
        "id": "UIxmiuD0ylMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'train': train,\n",
        "    'validation': valid,\n",
        "    'test': test,\n",
        "}\n",
        "\n",
        "dataset = datasets.DatasetDict(data)"
      ],
      "metadata": {
        "id": "j4LxMK78FUNL"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check final dataset"
      ],
      "metadata": {
        "id": "VlYmdv3Syp_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHXUojOmFs3s",
        "outputId": "d24d82bb-e4ca-4cc9-ed80-6bcee942cf48"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 40000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 5000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 5000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alternative approach using Datasets early"
      ],
      "metadata": {
        "id": "bmNw2x1RayOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positive_texts = open('imdb-positives.txt').readlines()\n",
        "negative_texts = open('imdb-negatives.txt').readlines()\n",
        "\n",
        "positive_examples = [{ 'text': text, 'label': 'positive' } for text in positive_texts]\n",
        "negative_examples = [{ 'text': text, 'label': 'negative' } for text in negative_texts]\n",
        "\n",
        "all_examples = positive_examples + negative_examples"
      ],
      "metadata": {
        "id": "BcyfoJiaQXX8",
        "outputId": "3cfeebb3-9bb3-4a6a-cefe-c08bd9f6013e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 50000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In order to use the 'stratify_by_label' argument, we need to assign features\n",
        "\n",
        "def make_dataset_modified(examples):\n",
        "  texts, labels = [], []\n",
        "  for e in examples:\n",
        "    texts.append(e['text'])\n",
        "    labels.append(e['label'])\n",
        "  data = {\n",
        "      'text': texts,\n",
        "      'label': labels\n",
        "  }\n",
        "  features = datasets.Features({\n",
        "      'text': datasets.Value('string'),\n",
        "      'label': datasets.ClassLabel(names=['negative', 'positive'])\n",
        "      })\n",
        "  return datasets.Dataset.from_dict(data, features)"
      ],
      "metadata": {
        "id": "RZshEVeaTc1h"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = make_dataset_modified(all_examples)"
      ],
      "metadata": {
        "id": "pOz5XrflTDz7"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now the dataset has features\n",
        "ds.features"
      ],
      "metadata": {
        "id": "0BhbPoA3SPdj",
        "outputId": "226d1a0f-56ae-42d1-c8b8-c72ce1b6e0f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': Value(dtype='string', id=None),\n",
              " 'label': ClassLabel(names=['negative', 'positive'], id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# And we can access the label names\n",
        "ds.features['label'].names"
      ],
      "metadata": {
        "id": "XtgJYSQYVXVE",
        "outputId": "781420e1-ebe7-48b6-df19-ee763e82c50a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['negative', 'positive']"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE! Now the class names have been mapped to 0 and 1\n",
        "ds[0]"
      ],
      "metadata": {
        "id": "Wv9zNDxyWGuf",
        "outputId": "10bbe329-bcd6-4b1a-8231-775ef23c23cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'Zentropa has much in common with The Third Man, another noir-like film set among the rubble of postwar Europe. Like TTM, there is much inventive camera work. There is an innocent American who gets emotionally involved with a woman he doesn\\'t really understand, and whose naivety is all the more striking in contrast with the natives.<br /><br />But I\\'d have to say that The Third Man has a more well-crafted storyline. Zentropa is a bit disjointed in this respect. Perhaps this is intentional: it is presented as a dream/nightmare, and making it too coherent would spoil the effect. <br /><br />This movie is unrelentingly grim--\"noir\" in more than one sense; one never sees the sun shine. Grim, but intriguing, and frightening.\\n',\n",
              " 'label': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we can split into train and test with stratification\n",
        "# Unlike sklearns train_test_split, this method return a DatasetDict\n",
        "ds_train_test = ds.train_test_split(train_size=0.8, stratify_by_column=\"label\")\n",
        "ds_train_test"
      ],
      "metadata": {
        "id": "xY5a7FvzQwup",
        "outputId": "2472f559-403e-44d4-a841-14f1443b8266",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 40000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 10000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the test set into valid and test\n",
        "ds_valid_test = ds_train_test['test'].train_test_split(test_size=0.5, stratify_by_column=\"label\")\n",
        "ds_valid_test"
      ],
      "metadata": {
        "id": "vplwYIWTUaKP",
        "outputId": "ab9ff515-9ba9-4a8e-833f-87f68e9812ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 5000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 5000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = datasets.DatasetDict({\n",
        "    'train': ds_train_test['train'],\n",
        "    'valid': ds_valid_test['train'],\n",
        "    'test': ds_valid_test['test']\n",
        "})\n",
        "data"
      ],
      "metadata": {
        "id": "6EDrmmFgUnRW",
        "outputId": "53d3e05a-6d53-45d6-9271-3cbab0fd7fa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 40000\n",
              "    })\n",
              "    valid: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 5000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 5000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cRn0qleUQZZh"
      }
    }
  ]
}