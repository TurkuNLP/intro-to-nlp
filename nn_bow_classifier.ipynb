{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "nn_bow_classifier.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/intro-to-nlp/blob/master/nn_bow_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJgSQnTr5hKs"
      },
      "source": [
        "# Bag-of-words document classification\n",
        "\n",
        "* BoW is the simplest way to do classification: Feature vector goes in, decision falls out.\n",
        "\n",
        "* Feature vector: a vector with as many dimensions as we have unique features, and a non-zero value set for every feature present in our example\n",
        "* Binary features: 1/0\n",
        "\n",
        "In the following we work with the IMDB data, have a look on [how to read it in](read_imdb.ipynb). Here we just read the ready data in.\n",
        "\n",
        "# IMDB data\n",
        "\n",
        "* Familiar data\n",
        "* Input vectorized as before\n",
        "* But now we will also have to turn class labels into integers and back explicitly so we can use Keras\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxbv7By-57T4",
        "outputId": "6533b13a-f39f-4158-a48a-adcf528972bb"
      },
      "source": [
        "!wget -nc https://github.com/TurkuNLP/intro-to-nlp/raw/master/Data/imdb_train.json"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-02 12:19:59--  https://github.com/TurkuNLP/intro-to-nlp/raw/master/Data/imdb_train.json\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/TurkuNLP/intro-to-nlp/master/Data/imdb_train.json [following]\n",
            "--2022-02-02 12:19:59--  https://raw.githubusercontent.com/TurkuNLP/intro-to-nlp/master/Data/imdb_train.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33944099 (32M) [text/plain]\n",
            "Saving to: ‘imdb_train.json’\n",
            "\n",
            "imdb_train.json     100%[===================>]  32.37M   125MB/s    in 0.3s    \n",
            "\n",
            "2022-02-02 12:20:00 (125 MB/s) - ‘imdb_train.json’ saved [33944099/33944099]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXG8Ca0e5hKz"
      },
      "source": [
        "import json\n",
        "import random\n",
        "with open(\"imdb_train.json\") as f:\n",
        "    data=json.load(f)\n",
        "random.shuffle(data) #play it safe!\n",
        "\n",
        "texts=[one_example[\"text\"] for one_example in data]\n",
        "labels=[one_example[\"class\"] for one_example in data]\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amrLFpve5hK0",
        "outputId": "323020eb-6820-4a4a-dbcb-874b280d786a"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_texts, dev_texts, train_labels, dev_labels=train_test_split(texts,labels,test_size=0.2)\n",
        "vectorizer=CountVectorizer(max_features=100000,binary=True,ngram_range=(1,1))\n",
        "feature_matrix_train=vectorizer.fit_transform(train_texts)\n",
        "feature_matrix_dev=vectorizer.transform(dev_texts)\n",
        "\n",
        "print(\"shape=\",feature_matrix_train.shape)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape= (20000, 68469)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTsbLacCAAAo"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def convert_sparse_matrix_to_sparse_tensor(X):\n",
        "    coo = X.tocoo()\n",
        "    indices = np.mat([coo.row, coo.col]).transpose()\n",
        "    return tf.sparse.reorder(tf.SparseTensor(indices, coo.data, coo.shape))\n",
        "\n",
        "feature_matrix_train_tf=convert_sparse_matrix_to_sparse_tensor(feature_matrix_train)\n",
        "feature_matrix_dev_tf=convert_sparse_matrix_to_sparse_tensor(feature_matrix_dev)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIluAddR5hK6"
      },
      "source": [
        "Now we have the feature matrix done! Next thing we need is the class labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EE7xaPp65hK7",
        "outputId": "c3eaa2ca-dfab-4b3f-a235-eb38fe88ae5e"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder=LabelEncoder() #Turns class labels into integers\n",
        "class_numbers_train=label_encoder.fit_transform(train_labels)\n",
        "class_numbers_dev=label_encoder.transform(dev_labels)\n",
        "\n",
        "print(\"class_numbers shape=\",class_numbers_train.shape)\n",
        "print(\"class labels\",label_encoder.classes_) #this will let us translate back from indices to labels"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class_numbers shape= (20000,)\n",
            "class labels ['neg' 'pos']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9Bo2pEq5hK8"
      },
      "source": [
        "* The data is ready :)\n",
        "\n",
        "We need to build the network now\n",
        "* Input\n",
        "* Hidden Dense layer with some kind of non-linearity, and a suitable number of nodes\n",
        "* Output Dense layer with the softmax activation (normalizes output to distribution) and as many nodes as there are classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLzFHV2d5hK8"
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "example_count,feature_count=feature_matrix_train.shape #how many examples and features we've got?\n",
        "example_count2=class_numbers_train.shape[0]\n",
        "assert example_count==example_count2 #sanity check\n",
        "class_count=len(label_encoder.classes_) #How many classes we've got?\n",
        "\n",
        "#Build the network:\n",
        "inp=Input(shape=(feature_count,)) #Input layer\n",
        "hidden=Dense(200,activation=\"tanh\")(inp) #Hidden layer\n",
        "outp=Dense(class_count,activation=\"softmax\")(hidden) #Output layer\n",
        "model=Model(inputs=[inp], outputs=[outp])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyIYRRvE5hK9"
      },
      "source": [
        "...it's **this** simple...!\n",
        "\n",
        "Once the model is constructed it needs to be compiled, for that we need to know:\n",
        "* which optimizer we want to use (sgd is fine to begin with)\n",
        "* what is the loss (sparse_categorial_crossentropy for multiclass of the kind we have is the right choice)\n",
        "* which metrics to measure, accuracy is an okay choice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2uv181F5hK-"
      },
      "source": [
        "model.compile(optimizer=\"sgd\",loss=\"sparse_categorical_crossentropy\",metrics=['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl2XExJk5hK-"
      },
      "source": [
        "A compiled model can be fitted on data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzZbwpRG5hK-",
        "outputId": "ddb6ecfb-4165-4f03-f78f-3a08491f2c97"
      },
      "source": [
        "\n",
        "\n",
        "hist=model.fit(feature_matrix_train_tf,class_numbers_train,\\\n",
        "               validation_data=(feature_matrix_dev_tf,class_numbers_dev),\\\n",
        "               batch_size=100,verbose=1,epochs=10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/dense/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/dense/embedding_lookup_sparse/Reshape:0\", shape=(None, 200), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/dense/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200/200 [==============================] - 5s 11ms/step - loss: 0.5721 - accuracy: 0.7712 - val_loss: 0.4909 - val_accuracy: 0.8154\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.4448 - accuracy: 0.8342 - val_loss: 0.4169 - val_accuracy: 0.8344\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 3s 12ms/step - loss: 0.3863 - accuracy: 0.8541 - val_loss: 0.3786 - val_accuracy: 0.8510\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.3505 - accuracy: 0.8644 - val_loss: 0.3537 - val_accuracy: 0.8586\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.3256 - accuracy: 0.8736 - val_loss: 0.3393 - val_accuracy: 0.8666\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.3065 - accuracy: 0.8812 - val_loss: 0.3265 - val_accuracy: 0.8684\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.2909 - accuracy: 0.8880 - val_loss: 0.3185 - val_accuracy: 0.8718\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.2777 - accuracy: 0.8946 - val_loss: 0.3125 - val_accuracy: 0.8714\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - 3s 15ms/step - loss: 0.2659 - accuracy: 0.8993 - val_loss: 0.3065 - val_accuracy: 0.8772\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - 4s 16ms/step - loss: 0.2554 - accuracy: 0.9036 - val_loss: 0.3024 - val_accuracy: 0.8790\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cbz1dBZI5hK_",
        "outputId": "a5f7b12e-262e-4a93-ccbf-88eb5eac15e5"
      },
      "source": [
        "print(hist.history[\"val_accuracy\"])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8154000043869019, 0.8343999981880188, 0.8510000109672546, 0.8586000204086304, 0.866599977016449, 0.868399977684021, 0.8718000054359436, 0.871399998664856, 0.8772000074386597, 0.8790000081062317]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5ln4rnH5hLA"
      },
      "source": [
        "* We ran for 10 epochs of training\n",
        "* Made it to a decent accuracy on the validation data\n",
        "\n",
        "* But we do not have the model saved, so let's fix that and get the whole thing done\n",
        "* What constitutes a model (ie what we need to run the model on new data)\n",
        "  - The feature dictionary in the vectorizer\n",
        "  - The list of classes in their correct order\n",
        "  - The structure of the network\n",
        "  - The weights the network learned\n",
        "\n",
        "* Do all these things, and run again. This time we also increase the number of epochs, see what happens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtLKUWW45hLA",
        "outputId": "80f54b35-a70e-4f5f-983c-7b68c6da2071"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "def save_model(file_name,model,label_encoder,vectorizer):\n",
        "    \"\"\"Saves model structure and vocabularies\"\"\"\n",
        "    model_json = model.to_json()\n",
        "    with open(file_name+\".model.json\", \"w\") as f:\n",
        "        print(model_json,file=f)\n",
        "    with open(file_name+\".encoders.pickle\",\"wb\") as f:\n",
        "        pickle.dump((label_encoder,vectorizer),f)\n",
        "            \n",
        "example_count,feature_count=feature_matrix_train_tf.shape #how many examples and features we've got?\n",
        "example_count2=class_numbers_train.shape[0]\n",
        "assert example_count==example_count2 #sanity check\n",
        "class_count=len(label_encoder.classes_) #How many classes we've got?\n",
        "\n",
        "#Build the network:\n",
        "inp=Input(shape=(feature_count,)) #Input layer\n",
        "hidden=Dense(200,activation=\"tanh\")(inp) #Hidden layer\n",
        "outp=Dense(class_count,activation=\"softmax\")(hidden) #Output layer\n",
        "model=Model(inputs=[inp], outputs=[outp])\n",
        "\n",
        "# Let's try a different optimizer!\n",
        "opt=optimizers.Adam()\n",
        "model.compile(optimizer=opt,loss=\"sparse_categorical_crossentropy\",metrics=['accuracy'])\n",
        "\n",
        "# Save model and vocabularies, can be done before training\n",
        "os.makedirs(\"models\",exist_ok=True)\n",
        "save_model(\"models/imdb_bow\",model,label_encoder,vectorizer)\n",
        "# Callback function to save weights during training, if validation loss goes down\n",
        "save_cb=ModelCheckpoint(filepath=\"models/imdb_bow.weights.h5\", monitor='val_loss',\\\n",
        "                        verbose=1, save_best_only=True, mode='auto')\n",
        "stop_cb=EarlyStopping(patience=2,verbose=1,restore_best_weights=True)\n",
        "hist=model.fit(feature_matrix_train_tf,class_numbers_train,\\\n",
        "               validation_data=(feature_matrix_dev_tf,class_numbers_dev),\\\n",
        "               batch_size=100,verbose=1,epochs=20,\\\n",
        "               callbacks=[save_cb,stop_cb])\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_4/dense_8/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_4/dense_8/embedding_lookup_sparse/Reshape:0\", shape=(None, 200), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_4/dense_8/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "198/200 [============================>.] - ETA: 0s - loss: 0.3258 - accuracy: 0.8636\n",
            "Epoch 00001: val_loss improved from inf to 0.28043, saving model to models/imdb_bow.weights.h5\n",
            "200/200 [==============================] - 7s 27ms/step - loss: 0.3250 - accuracy: 0.8640 - val_loss: 0.2804 - val_accuracy: 0.8868\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.9661\n",
            "Epoch 00002: val_loss did not improve from 0.28043\n",
            "200/200 [==============================] - 4s 22ms/step - loss: 0.0954 - accuracy: 0.9661 - val_loss: 0.3638 - val_accuracy: 0.8770\n",
            "Epoch 3/20\n",
            "199/200 [============================>.] - ETA: 0s - loss: 0.0329 - accuracy: 0.9895\n",
            "Epoch 00003: val_loss did not improve from 0.28043\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "200/200 [==============================] - 4s 21ms/step - loss: 0.0330 - accuracy: 0.9895 - val_loss: 0.5505 - val_accuracy: 0.8692\n",
            "Epoch 00003: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBKFuz2z5hLC",
        "outputId": "bb97cd66-4ae4-4e75-8028-1f66a636f455"
      },
      "source": [
        "import numpy\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "#Validation data used during training:\n",
        "val_instances,val_labels=feature_matrix_dev_tf,class_numbers_dev\n",
        "\n",
        "print(\"Network output=\",model.predict(val_instances))\n",
        "predictions=numpy.argmax(model.predict(val_instances),axis=1)\n",
        "print(\"Maximum class for each example=\",predictions)\n",
        "gold=val_labels\n",
        "conf_matrix=confusion_matrix(list(gold),list(predictions))\n",
        "print(\"Confusion matrix=\\n\",conf_matrix)\n",
        "\n",
        "gold_labels=label_encoder.inverse_transform(list(gold))\n",
        "predicted_labels=label_encoder.inverse_transform(list(predictions))\n",
        "#print(\"Gold labels=\",gold_labels)\n",
        "#print(\"Predicted labels=\",predicted_labels)\n",
        "print(classification_report(gold_labels,predicted_labels))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Network output= [[0.98579955 0.01420045]\n",
            " [0.00639336 0.9936067 ]\n",
            " [0.9461096  0.0538904 ]\n",
            " ...\n",
            " [0.00838413 0.99161583]\n",
            " [0.27300686 0.72699314]\n",
            " [0.95843035 0.04156965]]\n",
            "Maximum class for each example= [0 1 0 ... 1 1 0]\n",
            "Confusion matrix=\n",
            " [[2284  239]\n",
            " [ 327 2150]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.87      0.91      0.89      2523\n",
            "         pos       0.90      0.87      0.88      2477\n",
            "\n",
            "    accuracy                           0.89      5000\n",
            "   macro avg       0.89      0.89      0.89      5000\n",
            "weighted avg       0.89      0.89      0.89      5000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U691K9Gi5hLD"
      },
      "source": [
        "# Learning progress\n",
        "\n",
        "* The history object we get lets us inspect the accuracy during training\n",
        "* Remarks:\n",
        "  - Accuracy on training data keeps going up\n",
        "  - Accuracy on validation (test) data flattens out after a but over 10 epochs, we are learning very little past that point\n",
        "  - What we see is the network keeps overfitting on the training data to the end"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "rOZMQI8_5hLE",
        "outputId": "bf7461ce-6803-4707-e068-eed7a2c5a79a"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.ylim(0.55,1.0)\n",
        "plt.plot(hist.history[\"val_accuracy\"],label=\"Validation set accuracy\")\n",
        "plt.plot(hist.history[\"accuracy\"],label=\"Training set accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUH5yli05hLF"
      },
      "source": [
        "# Summary\n",
        "\n",
        "* We put together a program to train a neural network classifier for sentiment detector\n",
        "* We learned the necessary code/techniques to save models, and feed the training with data in just the right format\n",
        "* We observed the training across epochs\n",
        "* We saw how the classifier can be applied to various text classification problems\n",
        "* The IMDB sentiment classifier ended up at nearly 90% accuracy, the state of the art is about 95%, we got surprisingly far in few lines of code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjkMPuvnXwlT"
      },
      "source": [
        "# Save models in drive\n",
        "\n",
        "* The model is quite large, if you want to use it elsewhere, it makes sense to save it in Google Drive\n",
        "* Press \"Mount Drive\" under \"Files\" in top left corner and follow the instructions\n",
        "* Your drive will be mounted under /content/drive/MyDrive and you can then share the models across notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wdof6EKV1VZ",
        "outputId": "bf612aa2-e58b-4815-f630-deafb8a20a67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS7P2JgvWlhq"
      },
      "source": [
        "!mkdir -p /content/drive/MyDrive/intro-to-nlp/models-2022\n",
        "save_model(\"/content/drive/MyDrive/intro-to-nlp/models-2022/imdb_bow\",model,label_encoder,vectorizer)\n",
        "#and yet the weights!\n",
        "model.save(\"/content/drive/MyDrive/intro-to-nlp/models-2022/imdb_bow.weights.h5\")"
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}