{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/intro-to-nlp/blob/master/exercise14_2025_example_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exrcise 14: Text generation\n",
        "\n",
        "This example solution uses BSC-LT/salamandra-2b-instruct (instruction fine-tuned) and BSC-LT/salamandra-2b (pure LM) models without quantization.\n"
      ],
      "metadata": {
        "id": "tIQ1s96UCcJW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jwyK005xCFSF"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'BSC-LT/salamandra-2b-instruct'\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=MODEL_NAME)"
      ],
      "metadata": {
        "id": "wqTxn_QaCNjZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59446d1d-6670-4b6e-f782-b496660b6f6d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = [{\"role\": \"user\", \"content\": \"What is the capital of Finland?\"}] # we have only one message here, but we could also have a conversation with multiple user/assistant turns as a starting point\n",
        "\n",
        "output = pipe(conversation, max_new_tokens=50)\n",
        "\n",
        "for c in output[0][\"generated_text\"]:\n",
        "  print(f\"{c['role']}: {c['content']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWcOJkiKi5vr",
        "outputId": "87c3ecc7-1c8c-4aa6-921c-b1518facd89b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user: What is the capital of Finland?\n",
            "assistant: The capital city of Finland is Helsinki.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now restart the session to free memory. Then try the same with pure LM."
      ],
      "metadata": {
        "id": "YROp3hyikXPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "22QjXE88jkim"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'BSC-LT/salamandra-2b'\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=MODEL_NAME)"
      ],
      "metadata": {
        "id": "TztXyKeKXADq",
        "outputId": "ef817c02-ff31-4f62-d3fd-99289456e231",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on [model card](https://huggingface.co/BSC-LT/salamandra-2b), the input is string (or list of strings in case of multiple examples)."
      ],
      "metadata": {
        "id": "CNIKV2qI2UgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What is the capital of Finland?\"\n",
        "\n",
        "output = pipe(prompt, max_new_tokens=50)\n",
        "\n",
        "print(output[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCGf-BXh2HoV",
        "outputId": "b524a9fe-608d-4aad-a205-e92a9f78079c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the capital of Finland?\n",
            "The Finnish capital city Helsinki has a population of 630,597. The largest cities in Finland are Espoo (124,800), Vantaa (117,000) and Turku (10\n"
          ]
        }
      ]
    }
  ]
}